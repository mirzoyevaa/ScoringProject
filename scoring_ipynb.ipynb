{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install scorecardpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "7HsI3NKkTp2O",
        "outputId": "8193c1ed-1a18-450a-e99f-0725172c4ee9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime\n",
        "import scorecardpy as sc\n",
        "df_train = pd.read_csv('/Users/amirzoyeva/Desktop/scoring/tr_for_students.csv')\n",
        "\n",
        "\n",
        "\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Для удобства сразу переведем столбец issue_d в тип dt.date и оставим только год и месяц, чтобы было удобнее агрегировать и анализировать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train['issue_d'] = pd.to_datetime(df_train['issue_d']).dt.strftime('%Y-%m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.describe()\n",
        "#count - The number of not-empty values.\n",
        "# mean - The average (mean) value.\n",
        "# std - The standard deviation.\n",
        "# min - the minimum value.\n",
        "# 25% - The 25% percentile*.\n",
        "# 50% - The 50% percentile*.\n",
        "# 75% - The 75% percentile*.\n",
        "# max - the maximum value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Посмотрим, в каких категориях есть пропуски до заполнения\n",
        "missing_values_before = df_train.isna().sum()\n",
        "print(\"Пропуски до заполнения:\")\n",
        "print(missing_values_before)\n",
        "\n",
        "# Заполняем пропуски\n",
        "#если не заполнены данные о работе, то заполним пропуск строкой \"NAN\" и создадим новый столбец, в котором укажем на каких позициях было осуществлено заполнение\n",
        "df_train['emp_title_filled'] = np.where(df_train['emp_title'].isna(), 1, 0)\n",
        "\n",
        "# Заполним ропуски в столбце 'emp_title' строкой \"NAN\"\n",
        "df_train['emp_title'].fillna('NAN', inplace=True)\n",
        "\n",
        "#заполним пропуски в столбце 'emp_length' средним значением стажа на работе\n",
        "df_train['emp_length'].fillna(int(df_train['emp_length'].mean()), inplace=True)\n",
        "\n",
        "# пропуски в столбце 'mths_since_recent_inq' заполним минус единицами (кажется, что многие люди могли не заполнить это поле, потому что не брали займы до этого, \n",
        "# а так мы сможем ограничить такие случаи от людей, которые пытались получить займ совсем недавно)\n",
        "df_train['mths_since_recent_inq'].fillna(-1, inplace = True)\n",
        "# со столбцом num_accts_ever_120_pd и num_tl_90g_dpd_24m та же ситуация: кажется, что люди могли не указать этот параметр, так как не имеют таких задолженностей\n",
        "\n",
        "df_train['num_accts_ever_120_pd'].fillna(0, inplace = True)\n",
        "df_train['num_tl_90g_dpd_24m'].fillna(0, inplace = True)\n",
        "#столбец avg_cur_bal и tot_hi_cred_lim  заполним средним значением\n",
        "meann= df_train['avg_cur_bal'].mean()\n",
        "df_train['avg_cur_bal'].fillna(meann, inplace = True)\n",
        "mean2 = df_train['tot_hi_cred_lim'].mean()\n",
        "df_train['tot_hi_cred_lim'].fillna(mean2, inplace = True)\n",
        "# cтолбец acc_open_past_24mths  в местах пропуска тоже заполним нулями\n",
        "df_train['acc_open_past_24mths'].fillna(0, inplace = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Посмотрим, в каких категориях остались пропуски после заполнения\n",
        "missing_values_after = df_train.isna().sum()\n",
        "print(\"Пропуски после заполнения:\")\n",
        "print(missing_values_after)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Разделим признаки на категориальные и непрерывные:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical = []\n",
        "continuous = []\n",
        "for i in df_train.columns:\n",
        "    if ((df_train[i].dtype == int) or (df_train[i].dtype == float)):\n",
        "        continuous.append(i)\n",
        "    else:\n",
        "        categorical.append(i)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "continuous"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "scatter_trace = go.Scatter(x=df_train['chargeoff_within_12_mths'], y=df_train['annual_inc'], mode='markers')\n",
        "\n",
        "fig.add_trace(scatter_trace)\n",
        "\n",
        "fig.update_layout(\n",
        "    title='The relationship between annual income and the Number of charge-offs within 12 months',\n",
        "    yaxis_title='Annual Income',\n",
        "    xaxis_title='Number of charge-offs within 12 months'\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Рассмотрим распределение непрерывных переменных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "updatemenu = [dict()]\n",
        "buttons = []\n",
        "data = []\n",
        "fig_rasp = go.Figure()\n",
        "for i in continuous:\n",
        "    trace = px.histogram(df_train[i]).data[0]\n",
        "    trace.visible = False\n",
        "    data.append(trace) \n",
        "fig_rasp.add_traces(data) \n",
        "for i, col in enumerate(continuous):\n",
        "    visibles = [False] * len(continuous)\n",
        "    visibles[i] = True\n",
        "    buttons.append(dict(method='restyle',\n",
        "                        label=col,\n",
        "                        args=[{\"visible\": visibles}]\n",
        "                        ))\n",
        "\n",
        "updatemenu[0]['buttons'] = buttons\n",
        "updatemenu[0]['direction'] = 'down'\n",
        "updatemenu[0]['showactive'] = True\n",
        "\n",
        "fig_rasp.update_layout(showlegend=True, updatemenus=updatemenu)\n",
        "fig_rasp.update_layout(\n",
        "    title={\n",
        "        \"text\": \"Distribution of continuous variables\",\n",
        "        \"x\": 0.5\n",
        "    },\n",
        "    xaxis_title=\"Range\",\n",
        "    yaxis_title=\"Number of values\"\n",
        ")\n",
        "fig_rasp.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "fig_date = go.Figure()\n",
        "fig_date.add_trace(px.histogram(df_train['issue_d']).data[0])\n",
        "fig_date.update_layout(\n",
        "    title={\n",
        "        \"text\": \"Number of observations per month \",\n",
        "        \"x\": 0.5\n",
        "    },\n",
        "    xaxis_title=\"Month\",\n",
        "    yaxis_title=\"Number of observations\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "updatemenu = [dict()]\n",
        "buttons = []\n",
        "fig_cat= go.Figure()\n",
        "data = []  \n",
        "\n",
        "for i in categorical[1:]:\n",
        "    trace = px.histogram(df_train[i]).data[0]\n",
        "    trace.visible = False\n",
        "    data.append(trace) \n",
        "\n",
        "fig_cat.add_traces(data) \n",
        "for i, col in enumerate(categorical[1:]):\n",
        "    visibles = [False] * len(categorical[1:])\n",
        "    visibles[i] = True\n",
        "    buttons.append(dict(method='restyle',\n",
        "                        label=col,\n",
        "                        args=[{\"visible\": visibles}]\n",
        "                        ))\n",
        "\n",
        "updatemenu[0]['buttons'] = buttons\n",
        "updatemenu[0]['direction'] = 'down'\n",
        "updatemenu[0]['showactive'] = True\n",
        "\n",
        "fig_cat.update_layout(showlegend=True, updatemenus=updatemenu)\n",
        "fig_cat.update_layout(\n",
        "    title={\n",
        "        \"text\": \"Distribution of categorical variables\",\n",
        "        \"x\": 0.5\n",
        "    },\n",
        "    xaxis_title=\"Value\",\n",
        "    yaxis_title=\"Number of values\"\n",
        ")\n",
        "fig_cat.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df1 = df_train.groupby(['emp_length']).agg({'delinq_2yrs': 'sum'}).reset_index()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=df1, x='emp_length', y='delinq_2yrs')\n",
        "plt.title('Number of late payments by number of years of work')\n",
        "plt.xlabel('Work experience (years)')\n",
        "plt.ylabel('Number of delays')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2 = df_train.groupby('emp_length')['def'].value_counts()\n",
        "df2 = df2.reset_index(name='count')\n",
        "fig_def_emp = go.Figure()\n",
        "fig_targ_rate = go.Figure()\n",
        "\n",
        "dfD = df2[df2['def'] == 1]\n",
        "dfN = df2[df2['def'] == 0]\n",
        "df_rate = pd.merge(dfD, dfN, on =['emp_length'])\n",
        "\n",
        "traceD = go.Bar(\n",
        "    x=dfD['emp_length'],\n",
        "    y=dfD['count'],\n",
        "    name='Default',\n",
        "    marker=dict(color=\"Blue\"),\n",
        "    text=dfD['count']\n",
        ")\n",
        "traceN = go.Bar(\n",
        "    x=dfN['emp_length'],\n",
        "    y=dfN['count'],\n",
        "    name='Non-default',\n",
        "    marker=dict(color=\"Red\"),\n",
        "    text=dfN['count']\n",
        ")\n",
        "\n",
        "data = [traceD, traceN]\n",
        "\n",
        "fig_def_emp.add_traces(data)\n",
        "    \n",
        "fig_def_emp.update_layout(\n",
        "    title={\n",
        "        \"text\": \"Number of default / nondefault loans by employment length\",\n",
        "        \"x\": 0.5\n",
        "    },\n",
        "    xaxis_title=\"Employment lengt\",\n",
        "    yaxis_title=\"Number of loans\"\n",
        "\n",
        ")\n",
        "fig_def_emp.show()\n",
        "\n",
        "df_rate['perc']= (df_rate['count_x']\t/ df_rate['count_y'])*100\n",
        "trace1 = go.Bar(\n",
        "    x=df_rate['emp_length'],\n",
        "    y=df_rate['perc'],\n",
        "    name='Target rate',\n",
        "    text=df_rate['perc']\n",
        ")\n",
        "fig_targ_rate.add_trace(trace1)\n",
        "fig_targ_rate.update_layout(\n",
        "    title={\n",
        "        \"text\": \"Target rate by employment length\",\n",
        "        \"x\": 0.5\n",
        "    },\n",
        "    xaxis_title=\"Employment lengt\",\n",
        "    yaxis_title=\"Target rate\"\n",
        "\n",
        ")\n",
        "fig_targ_rate.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df3 = df_train.groupby('home_ownership')['def'].value_counts()\n",
        "df3 = df3.reset_index(name='count')\n",
        "fig_def_home = go.Figure()\n",
        "fig_targ_rate_2 = go.Figure()\n",
        "\n",
        "dfD = df3[df3['def'] == 1]\n",
        "dfN = df3[df3['def'] == 0]\n",
        "df_rate_2 = pd.merge(dfD, dfN, on =['home_ownership'])\n",
        "traceD = go.Bar(\n",
        "    x=dfD['home_ownership'],\n",
        "    y=dfD['count'],\n",
        "    name='Default',\n",
        "    marker=dict(color=\"Blue\"),\n",
        "    text=dfD['count']\n",
        ")\n",
        "traceN = go.Bar(\n",
        "    x=dfN['home_ownership'],\n",
        "    y=dfN['count'],\n",
        "    name='Non-default',\n",
        "    marker=dict(color=\"Red\"),\n",
        "    text=dfN['count']\n",
        ")\n",
        "\n",
        "data = [traceD, traceN]\n",
        "\n",
        "fig_def_home.add_traces(data)\n",
        "    \n",
        "fig_def_home.update_layout(\n",
        "    title={\n",
        "        \"text\": \"Number of default / nondefault loans by homeownership status\",\n",
        "        \"x\": 0.5\n",
        "    },\n",
        "    xaxis_title=\"Home ownership status\",\n",
        "    yaxis_title=\"Number of loans\"\n",
        "\n",
        ")\n",
        "fig_def_home.show()\n",
        "\n",
        "df_rate_2['perc']= (df_rate_2['count_x']\t/ df_rate_2['count_y'])*100\n",
        "trace2 = go.Bar(\n",
        "    x=df_rate_2['home_ownership'],\n",
        "    y=df_rate_2['perc'],\n",
        "    name='Target rate',\n",
        "    text=df_rate_2['perc']\n",
        ")\n",
        "fig_targ_rate_2.add_trace(trace2)\n",
        "fig_targ_rate_2.update_layout(\n",
        "    title={\n",
        "        \"text\": \"Target rate by home ownership status\",\n",
        "        \"x\": 0.5\n",
        "    },\n",
        "    xaxis_title=\"Home ownership status\",\n",
        "    yaxis_title=\"Target rate\"\n",
        "\n",
        ")\n",
        "fig_targ_rate_2.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objs as go\n",
        "\n",
        "random_20 = df_train.sample(n=20, random_state=42)\n",
        "sorted_rows = random_20.sort_values(by='annual_inc')\n",
        "\n",
        "fig2 = go.Figure()\n",
        "\n",
        "\n",
        "fig2.add_trace(go.Scatter(x=sorted_rows['annual_inc'], y=sorted_rows['installment'], mode='markers'))\n",
        "\n",
        "fig2.update_layout(\n",
        "    title='Relationship between annual income and monthly payment',\n",
        "    xaxis_title='Annual Income',\n",
        "    yaxis_title='Installment'\n",
        ")\n",
        "\n",
        "fig2.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Также необходимо посмотреть на корреляцию непрерывных переменных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Теперь попробуем сгенерировать некоторые новые признаки\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "continuous.remove('def')\n",
        "continuous \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_without_cat = df_train.drop(categorical, axis = 1)\n",
        "df_without_cat\n",
        "df_without_cont = df_train.drop(continuous, axis = 1)\n",
        "df_without_cont"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Попробуем вернуться к зависимости между годовым доходом и месячным платежом, который полагается заемщику в случае выдачи займа. В новый признак запишем процент, который будет занимать месячный платеж от среднего месячного дохода "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train['perc_month'] = (df_train['installment']/(df_train['annual_inc']/12))*100\n",
        "continuous.append('perc_month')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = df_train.drop(['emp_title'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Так же сгенерируем новые признаки на основе категориальных перменных:\n",
        "нам неудобно работать с переменными, которые представлены строками, поэтому нам необходимо создать фиктивные переменные, такие что новые столбцы будут состоять из булевых переменных. Единицы будут стоять в тех строках, если соответствующее столбцу категориальная переменная принимает именно то значение, которое прописано в столбце:\n",
        "Однако мы не будем делать такие переменные для всех категориальных признаков, например, переменные addr_state, purpose, sub_grade и emp_title принимают слишком много значений (посмотрим на графике распределения категориальных переменных), значит у нас будет слишком много столбцов, не несущих особого смысла. Также поступим и с issue_d.\n",
        "\n",
        "Addr_state, purpose, sub_grade и emp_title мы преобразуем так: с помощью category_encoders построим биекцию из множества значений, принимаемых переменной в множество натуральных чисел"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import category_encoders as ce\n",
        "encoder = ce.OrdinalEncoder(cols=['issue_d','purpose', 'addr_state', 'sub_grade'])\n",
        "df_train = encoder.fit_transform(df_train)\n",
        "df_train_woe = df_train\n",
        "encoder = ce.OrdinalEncoder(cols=['home_ownership'])\n",
        "df_train = encoder.fit_transform(df_train)\n",
        "df_train = df_train.drop(['issue_d'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# a = pd.get_dummies(df_train, columns = ['home_ownership'], drop_first=True)\n",
        "# df_train = a\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь поделим наш датасет на тренировочную и валидационную выборку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "target_train  = df_train['def']\n",
        "df_train_lg = df_train.drop(['def'], axis=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(df_train_lg, target_train, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Масштабирование  и обучение модели ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "Xtr_scaled = scaler.fit_transform(X_train)\n",
        "Xval_scaled = scaler.transform(X_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучим модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model =  LogisticRegression(random_state=0, penalty='l2')\n",
        "model.fit(Xtr_scaled, y_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь предскажем результаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = model.predict(Xval_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Теперь оценим наши результаты с помощью матрицы ошибок\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "conf_m= confusion_matrix(y_val, y_pred)\n",
        "\n",
        "cm_matrix = pd.DataFrame(data=conf_m)\n",
        "sns.heatmap(cm_matrix, annot=True, fmt='d')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Основные показатели модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('accuracy_score= {:.3f}'.format(accuracy_score(y_val, y_pred)))\n",
        "print('recall_score = {:.3f}'.format(recall_score(y_val, y_pred)))\n",
        "print('precision_score = {:.3f}'.format(precision_score(y_val, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Далее оценим нашу модель с помощью показателя ROC-AUC:\n",
        "Однако, для этого нам нужно получить вероятности принадлежности каждого заемщика (вектор признаков в нашем случае) к классу 0 (\"нет дефолта\") и 1 (\"дефолт\"). Для этого воспользуюсь функцией ```predict_proba```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lr_probs = model.predict_proba(Xtr_scaled)\n",
        "lr_probs_val = model.predict_proba(Xval_scaled)\n",
        "lr_probs = lr_probs[:, 1]\n",
        "lr_probs_val = lr_probs_val[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train_perf = sc.perf_eva(y_train,lr_probs ,plot_type = [\"roc\"], title = \"train\")\n",
        "test_perf = sc.perf_eva(y_val,lr_probs_val ,plot_type = [\"roc\"], title = \"test\")\n",
        "print('Gini coeff train  = ' , train_perf['Gini'])\n",
        "print('Gini coeff test  =' , test_perf['Gini'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Как видно, пока наша модель имеет показатель AUC = 0.67"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# WOE преобразования\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_woe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train_woe = df_train_woe.drop(['sub_grade','addr_state'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "breaks_list = {\n",
        "    'mths_since_recent_inq' : [5, 15, 20, float('inf') ],\n",
        "    'delinq_amnt': [0, 100,500, float('inf')],\n",
        "    'num_tl_90g_dpd_24m':[0,1,4, float('inf')],\n",
        "    'chargeoff_within_12_mths': [0,1,3],\n",
        "    \n",
        "}\n",
        "\n",
        "\n",
        "bins = sc.woebin(df_train_woe,\n",
        "                 special_values={\n",
        "        'home_ownership': [1, 2, 3, 4, 5],\n",
        "        'emp_title_filled': [0,1],\n",
        "        'term':[36,60]\n",
        "    },\n",
        "    breaks_list=breaks_list,\n",
        "    y=\"def\") \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_ivs= {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for variable_bins in bins:\n",
        "    total_ivs[variable_bins] = bins[variable_bins]['total_iv'][0]\n",
        "print(total_ivs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Удалим из датафрейма те значения,  у которых IV < 0.05:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "threshold = 0.01\n",
        "filtered_dict = {key: value for key, value in total_ivs.items() if value >= threshold}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sc.woebin_plot(bins)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_train_woe  = df_train_woe['def']\n",
        "\n",
        "df_train_woe = df_train_woe.drop(['def'], axis=1)\n",
        "df_train_woe = df_train_woe.filter(items=filtered_dict.keys())\n",
        "df_train_woe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_woe, X_val_woe, y_train_woe, y_val_woe = train_test_split(df_train_woe, target_train_woe, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_woe = sc.woebin_ply(X_train_woe, bins)\n",
        "test_woe = sc.woebin_ply(X_val_woe, bins)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model =  LogisticRegression(random_state=0, penalty='l2')\n",
        "model.fit(train_woe, y_train_woe)\n",
        "test_pred = model.predict_proba(test_woe)[:,1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "test_perf_woe = sc.perf_eva(y_val_woe, test_pred, plot_type = [\"roc\"], title = \"test\")\n",
        "print('Gini coeff test  =' , test_perf_woe['Gini'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
